# Song Lyrics Embedding & Weaviate Indexing Pipeline

A production-ready, optimized pipeline for processing millions of song lyrics, generating embeddings using Azure OpenAI, and indexing them into Weaviate for semantic search.

## âœ¨ Features

- ğŸš€ **Optimized Performance**: Pipelined embeddings and indexing (30% faster)
- ğŸ”„ **Resume Capability**: Checkpoint system to resume from interruptions
- â˜ï¸ **Azure OpenAI Support**: Full support for Azure OpenAI embeddings
- ğŸ“Š **Progress Tracking**: Real-time progress bars and detailed logging
- ğŸ” **Proper Schema**: Weaviate schema with optimized tokenization
- âš¡ **Async Processing**: Concurrent embeddings with rate limiting
- ğŸ›¡ï¸ **Error Handling**: Comprehensive error handling with retry logic

## ğŸ“‹ Requirements

- Python 3.11+
- Azure OpenAI account (or regular OpenAI)
- Weaviate instance (local or cloud)
- CSV file with song lyrics

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone <your-repo-url>
cd nthScaling
```

### 2. Install Dependencies

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Configure Credentials

```bash
# Copy the example config
cp config.example.py config.py

# Edit config.py with your credentials
nano config.py
```

Update these values in `config.py`:
- `AZURE_OPENAI_API_KEY` - Your Azure OpenAI API key
- `AZURE_OPENAI_ENDPOINT` - Your Azure OpenAI endpoint URL
- `AZURE_OPENAI_DEPLOYMENT_NAME` - Your deployment name
- `WEAVIATE_URL` - Your Weaviate instance URL

### 4. Get Your Data

Download or place your CSV file:
```bash
# Your CSV should have these columns:
# title, tag, artist, year, views, features, lyrics, id, 
# language_cld3, language_ft, language
```

### 5. Verify Setup

```bash
python verify_setup.py
```

### 6. Create Weaviate Schema

```bash
python create_weaviate_schema.py
```

### 7. Test with Sample Data

```bash
python test_pipeline.py
```

### 8. Run Full Pipeline

```bash
python process_lyrics.py
```

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| `AZURE_OPENAI_SETUP.md` | Complete Azure OpenAI setup guide |
| `QUICK_CONFIG_AZURE.txt` | One-page configuration reference |
| `TESTING_GUIDE.md` | Guide to all test scripts |
| `PERFORMANCE_OPTIMIZATION.md` | Details on pipelining optimization |
| `SYNC_VS_ASYNC_ANALYSIS.md` | Analysis of sync vs async operations |

## ğŸ”§ Configuration

### Key Settings in `config.py`

```python
# Processing speed
CHUNK_SIZE = 10000          # Read 10k rows at a time
BATCH_SIZE = 10             # Process 10 rows at a time
MAX_CONCURRENT_EMBEDDINGS = 10  # Concurrent API calls

# Azure OpenAI
USE_AZURE_OPENAI = True     # True for Azure, False for OpenAI
AZURE_OPENAI_API_KEY = "your-key"
AZURE_OPENAI_ENDPOINT = "https://your-resource.openai.azure.com/"
```

## ğŸ“Š Pipeline Architecture

```
CSV File (3M rows)
    â†“
Read in 10k chunks
    â†“
Process 10 rows at a time
    â†“
â”œâ”€â†’ Clean & Validate Data
â”œâ”€â†’ Generate Embeddings (10 concurrent async requests)
â””â”€â†’ Batch Index to Weaviate
    â†“
Update Checkpoint (Resume capability)
    â†“
Repeat until complete
```

### Pipelined Processing

```
Batch 1: [Embed 10s] [Index 3s]
Batch 2:         [Embed 10s] â† Overlaps! [Index 3s]
Batch 3:                  [Embed 10s] â† Overlaps!

Result: 30% faster processing!
```

## ğŸ—‚ï¸ Project Structure

```
nthScaling/
â”œâ”€â”€ config.example.py           # Configuration template (COPY TO config.py)
â”œâ”€â”€ process_lyrics.py           # Main processing script
â”œâ”€â”€ create_weaviate_schema.py   # Create Weaviate schema
â”œâ”€â”€ verify_setup.py             # Test connections
â”œâ”€â”€ test_pipeline.py            # End-to-end test with sample data
â”œâ”€â”€ check_progress.py           # Monitor processing progress
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ AZURE_OPENAI_SETUP.md      # Azure setup guide
â”œâ”€â”€ TESTING_GUIDE.md           # Testing documentation
â””â”€â”€ PERFORMANCE_OPTIMIZATION.md # Performance details
```

## ğŸ¯ Scripts Overview

| Script | Purpose | When to Use |
|--------|---------|-------------|
| `verify_setup.py` | Test connections | First time setup |
| `create_weaviate_schema.py` | Create schema | Before indexing |
| `test_pipeline.py` | Test with 5 rows | Before production |
| `process_lyrics.py` | Process all data | Production run |
| `check_progress.py` | Check status | During processing |

## âš¡ Performance

- **Processing Speed**: ~100-200 rows/minute (depends on API limits)
- **Memory Usage**: ~500MB - 1GB
- **Optimization**: 30% faster with pipelined processing
- **Resume**: Automatic checkpoint every batch

### For 3 Million Rows:
- **Estimated Time**: ~35 days (with optimization)
- **Without Optimization**: ~45 days
- **Savings**: 10 days âš¡

## ğŸ” Weaviate Schema

### Searchable Fields (Word Tokenization)
- `title` - Full-text search
- `lyrics` - Full-text search

### Filterable Fields (Field Tokenization)
- `artist`, `tag`, `features`, `song_id`
- `language_cld3`, `language_ft`, `language`
- `year`, `views` (numeric)

### Vector Configuration
- **Model**: text-embedding-3-large (3072 dimensions)
- **Index**: HNSW with cosine distance
- **WAND**: Disabled for accurate scoring

## ğŸ›¡ï¸ Security

- âœ… `config.py` is in `.gitignore` (never committed)
- âœ… Use `config.example.py` as template
- âœ… CSV/ZIP files excluded from git
- âœ… Checkpoint files excluded from git

## ğŸ“ˆ Monitoring

### Check Progress
```bash
python check_progress.py
```

### View Logs
```bash
tail -f processing_log.log
```

### Resume After Interruption
Simply run again - it will resume automatically:
```bash
python process_lyrics.py
```

## ğŸ› Troubleshooting

### Connection Issues
```bash
# Test connections first
python verify_setup.py

# Check Weaviate is running
curl http://localhost:8080/v1/.well-known/ready
```

### Rate Limiting
Reduce concurrent requests in `config.py`:
```python
MAX_CONCURRENT_EMBEDDINGS = 5  # Lower for free tier
```

### Memory Issues
Reduce chunk size in `config.py`:
```python
CHUNK_SIZE = 5000  # Instead of 10000
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## ğŸ“ License

[Your License Here]

## ğŸ™ Acknowledgments

- Azure OpenAI for embeddings
- Weaviate for vector database
- OpenAI Python SDK

## ğŸ“§ Contact

[Your contact information]

---

**Note**: Make sure to configure `config.py` with your credentials before running. Never commit `config.py` to version control!
